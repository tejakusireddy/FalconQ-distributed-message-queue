# distributed-message-queue
A fault-tolerant distributed message queue system inspired by Kafka, with priority messaging, replication, and real-time monitoring.
# ğŸ¦… FalconQ â€“ Distributed Message Queue with Priority-Based Messaging

FalconQ is a high-performance distributed message queue inspired by Apache Kafka, built in Go. It supports topic-based pub/sub, queue-based consumption, consumer offset tracking, and **priority-aware message delivery** â€” all from scratch.

> ğŸš€ Designed to showcase system design, distributed systems, and production-level Go backend skills. FAANG-ready. 

---

## ğŸ“¦ Features

- âœ… **Topic-based publish/subscribe** via REST API
- âœ… **High vs Low priority queueing**
- âœ… **Offset-tracked consumption** per consumer ID
- âœ… **Partitioned architecture** (starting with partition 0)
- âœ… **In-memory data store** (RocksDB coming soon)
- âœ… **Batch consumption support**
- âœ… **Admin endpoints** for topic/partition insights
- ğŸ”œ RocksDB persistence
- ğŸ”œ Raft-based replication
- ğŸ”œ Prometheus + Grafana observability
- ğŸ”œ Chaos testing & 1.5M msg/min stress test

---

## ğŸš¦ API Endpoints

| Method | Route | Description |
|--------|-------|-------------|
| `POST` | `/topic/:topic/publish` | Publish a message (JSON: `message`, `priority`) |
| `GET`  | `/topic/:topic/consume?consumerID=X&batch=N` | Consume N messages (offset tracked) |
| `GET`  | `/topic/:topic/peek?offset=X&batch=N` | Peek messages without consuming |
| `GET`  | `/topics` | List all topics |
| `GET`  | `/topics/:topic/partitions` | View partition stats (message count, etc.) |

---

## ğŸ§ª Example Usage (cURL)


# Publish messages
curl -X POST http://localhost:8080/topic/orders/publish \
  -H "Content-Type: application/json" \
  -d '{"message": "ğŸ”¥ Urgent refund", "priority": "high"}'

curl -X POST http://localhost:8080/topic/orders/publish \
  -H "Content-Type: application/json" \
  -d '{"message": "ğŸ§Š Normal order", "priority": "low"}'

# Consume
curl "http://localhost:8080/topic/orders/consume?consumerID=worker1&batch=1"

# Peek
curl "http://localhost:8080/topic/orders/peek?offset=0&batch=5"

# View topics/partitions
curl http://localhost:8080/topics
curl http://localhost:8080/topics/orders/partitions


ğŸ§  Architecture
mermaid

graph TD

  Broker --> TopicOrders[Topic: orders]
  Broker --> TopicPayments[Topic: payments]

  TopicOrders --> Partition0Orders[Partition 0]
  TopicPayments --> Partition0Payments[Partition 0]

  Partition0Orders --> HighQueue1[High Priority Queue]
  Partition0Orders --> LowQueue1[Low Priority Queue]
  Partition0Orders --> Offsets1[Consumer Offsets]

  Partition0Payments --> HighQueue2[High Priority Queue]
  Partition0Payments --> LowQueue2[Low Priority Queue]
  Partition0Payments --> Offsets2[Consumer Offsets]

  subgraph API Endpoints
    Publish[POST /topic/:topic/publish]
    Peek[GET /topic/:topic/peek]
    Consume[GET /topic/:topic/consume]
    Topics[GET /topics]
    Partitions[GET /topics/:topic/partitions]
  end

  Publish --> Broker
  Peek --> Broker
  Consume --> Broker
  Topics --> Broker
  Partitions --> Broker

ğŸ› ï¸ Tech Stack
Language: Go

Framework: Gin (for REST API)

Data Store: In-memory (Phase 1), RocksDB (Phase 2)

Coordination: Planned Raft via hashicorp/raft

Observability: Planned Prometheus + Grafana

ğŸ›£ï¸ Roadmap
 Phase 1 â€“ In-memory priority queue, REST APIs

 Phase 2 â€“ Add persistent log with RocksDB

 Phase 3 â€“ Partitioning with consistent hashing

 Phase 4 â€“ Raft-based leader election and replication

 Phase 5 â€“ Kubernetes (EKS) deployment + Chaos Mesh

 Phase 6 â€“ Metrics, Tracing, Dashboard

ğŸ‘¨â€ğŸ’» Author
Sai Teja Kusireddy

ğŸ License
MIT â€” feel free to fork, star, and build on top of it.

---







