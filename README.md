# ğŸ¦… FalconQ â€“ Distributed Message Queue with Priority-Based Messaging

![Go Version](https://img.shields.io/badge/Go-1.18+-brightgreen?logo=go)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Status](https://img.shields.io/badge/Project-Active-brightgreen)
![PRs Welcome](https://img.shields.io/badge/PRs-welcome-blue.svg)
![Stars](https://img.shields.io/github/stars/tejakusireddy/FalconQ-distributed-message-queue?style=social)

FalconQ is a high-performance distributed message queue inspired by Apache Kafka, built in Go. It supports topic-based pub/sub, queue-based consumption, consumer offset tracking, **persistent storage**, **Raft-based consensus**, and **priority-aware message delivery** â€” all from scratch.

> ğŸš€ Designed to showcase system design, distributed systems, and production-level Go backend skills. FAANG-ready.

---

## ğŸ“¦ Features

- âœ… **Topic-based publish/subscribe** via REST API
- âœ… **High vs Low priority queueing** (handled during consumption)
- âœ… **Offset-tracked consumption** per consumer ID
- âœ… **Persistent Commit Log** using **BadgerDB**
- âœ… **Per-partition Raft leader election & replication**
- âœ… **Partitioning via Consistent Hashing + Round Robin fallback**
- âœ… **Batch consumption support**
- âœ… **Admin endpoints** for topic/partition/raft stats
- ğŸ”œ Prometheus + Grafana observability
- ğŸ”œ Chaos testing & 1.5M msg/min stress testing

---

---

## ğŸš€ Getting Started

1.  **Prerequisites:**
    *   Go (version 1.18+ recommended) installed.
2.  **Clone the repository:**
    git clone https://github.com/tejakusireddy/FalconQ-distributed-message-queue.git
    cd falconq
3.  **Install dependencies:**
    go mod tidy
4.  **Update config.yaml with Raft & HTTP addresses for all nodes:**
5.  **Run 3 nodes (each in a separate terminal):**
    Make sure you are in the root directory of the project
    Terminal 1
     go run broker/main.go -config broker/config.yaml -nodeid node1

    Terminal 2
     go run broker/main.go -config broker/config.yaml -nodeid node2

    Terminal 3
     go run broker/main.go -config broker/config.yaml -nodeid node3
    
6.  **Use `curl` (or other tools) to interact with the API** (see examples below).

---

## ğŸš¦ API Endpoints

| Method | Route                                       | Description                                     |
|--------|---------------------------------------------|-------------------------------------------------|
| `POST` | `/topic/:topic/publish`                     | Publish a message (JSON: `message`, `priority`) |
| `GET`  | `/topic/:topic/consume?consumerID=X&batch=N`| Consume N messages (offset tracked)             |
| `GET`  | `/topic/:topic/peek?offset=X&batch=N`       | Peek messages starting at offset (no consumption) |
| `GET`  | `/topics`                                   | List all active topic names                     |
| `GET`  | `/topics/:topic/partitions`                 | View partition IDs for a specific topic         |
---

### ğŸ§ª Example Usage (CURL)

#### Publish messages to the 'orders' topic
curl -X POST http://localhost:8080/topic/orders/publish \
  -H "Content-Type: application/json" \
  -d '{"message": "ğŸ”¥ Urgent refund request #RF001", "priority": "high"}'

curl -X POST http://localhost:8080/topic/orders/publish \
  -H "Content-Type: application/json" \
  -d '{"message": "ğŸ§Š Normal order placement #ORD001", "priority": "low"}'

curl -X POST http://localhost:8080/topic/orders/publish \
  -H "Content-Type: application/json" \
  -d '{"message": "ğŸ”¥ Critical stock update #SKU001", "priority": "high"}'

Consume messages for consumer 'worker1' (gets high priority first)
First call:
curl "http://localhost:8080/topic/orders/consume?consumerID=worker1&batch=2"
Example Response: 
[{"v":"ğŸ”¥ Urgent refund request #RF001","p":"high","Offset":0},{"v":"ğŸ”¥ Critical stock update #SKU001","p":"high","Offset":2}], nextOffset: 3

Second call (will get low priority if available):
curl "http://localhost:8080/topic/orders/consume?consumerID=worker1&batch=2"
Example Response: 
[{"v":"ğŸ§Š Normal order placement #ORD001","p":"low","Offset":1}], nextOffset: 2 (Note: actual offset depends on internal filtering)


Peek messages starting from offset 0 (gets high priority first)
curl "http://localhost:8080/topic/orders/peek?offset=0&batch=5"

View topics/partitions
curl http://localhost:8080/topics
Example Response: {"topics":["orders"]}

curl http://localhost:8080/topics/orders/partitions
Example Response: {"partitions":[{"id":0}],"topic":"orders"}



ğŸ§  Architecture 


Architecture below illustrates how messages flow from REST â†’ Broker â†’ BadgerDB

```mermaid
graph TD
  subgraph "User Facing API - Gin"
    Publish[POST /topic/:topic/publish]
    Peek[GET /topic/:topic/peek]
    Consume[GET /topic/:topic/consume]
    Topics[GET /topics]
    Partitions[GET /topics/:topic/partitions]
  end
```

```mermaid
graph TD
  subgraph "Broker Logic - Go"
    Broker -- Manages --> TopicsMap{{Topics Map}}
    TopicsMap --> TopicOrders(Topic: orders)
    TopicsMap --> TopicPayments(Topic: payments)
    TopicOrders -- Contains --> Partition0Orders(Partition 0)
    TopicPayments -- Contains --> Partition0Payments(Partition 0)
    Partition0Orders -- Manages --> OffsetsOrders[In-Memory Consumer Offsets]
    Partition0Orders -- Writes/Reads Log --> BadgerDB[(BadgerDB Persistent KV Store)]
    Partition0Payments -- Manages --> OffsetsPayments[In-Memory Consumer Offsets]
    Partition0Payments -- Writes/Reads Log --> BadgerDB
  end
```




  Publish --> Broker  
  Peek --> Broker  
  Consume --> Broker  
  Topics --> Broker  
  Partitions --> Broker  


ğŸ› ï¸ Tech Stack  
Language: Go  
Framework: Gin (for REST API)  
Data Store: BadgerDB (Persistent Key-Value Store / Commit Log)  
Coordination: Planned Raft via hashicorp/raft  
Observability: Planned Prometheus + Grafana  


ğŸ›£ï¸ Roadmap  
âœ… Phase 1 â€“ In-memory priority queue concept, REST APIs  
âœ… Phase 2 â€“ Add persistent commit log with BadgerDB  
âœ… Phase 3 â€“ Partitioning implementation (Consistent Hashing)  
âœ… Phase 4 â€“ Raft-based leader election and replication  
â¡ï¸ Phase 5 â€“ Kubernetes (EKS) deployment + Chaos Mesh  
â¡ï¸ Phase 6 â€“ Metrics, Tracing, Dashboard  


ğŸ‘¨â€ğŸ’» Authors  
Sai Teja Kusireddy    
Snehith Kongara  

ğŸ License
MIT â€” feel free to fork, star, and build on top of it.


---







